# main.py
import torch
import cv2
import numpy as np
import mss
import pyautogui
import keyboard
import time

# 1. YOLOv5 ëª¨ë¸ ë¡œë“œ (ì‚¬ì „í•™ìŠµëœ YOLOv5s)
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)
model.conf = 0.4  # confidence threshold

# 2. ê°ì§€ ëŒ€ìƒ
TARGET_CLASSES = ['person', 'car', 'truck', 'bus', 'motorbike']

# 3. í™”ë©´ ìº¡ì²˜ ì„¤ì •
monitor = {"top": 100, "left": 100, "width": 800, "height": 600}
sct = mss.mss()

def capture_screen():
    img = np.array(sct.grab(monitor))
    return cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)

def detect_objects(frame):
    results = model(frame)
    detections = results.pandas().xyxy[0]
    return detections[detections['name'].isin(TARGET_CLASSES)]

def decide_direction(detections, frame_width):
    left_count = 0
    right_count = 0
    for _, row in detections.iterrows():
        center_x = (row['xmin'] + row['xmax']) / 2
        if center_x < frame_width / 2:
            left_count += 1
        else:
            right_count += 1

    if left_count > right_count:
        return 'right'
    elif right_count > left_count:
        return 'left'
    else:
        return 'forward'

def press_key(direction):
    keyboard.release('a')
    keyboard.release('d')

    if direction == 'left':
        keyboard.press('a')
        print("â¬…ï¸ ì™¼ìª½ìœ¼ë¡œ íšŒí”¼")
    elif direction == 'right':
        keyboard.press('d')
        print("â¡ï¸ ì˜¤ë¥¸ìª½ìœ¼ë¡œ íšŒí”¼")
    else:
        print("â¬†ï¸ ì „ì§„")

# 4. ë£¨í”„ ì‹¤í–‰
print("ğŸš— ììœ¨ì£¼í–‰ ì‹œì‘... ESCë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•˜ì„¸ìš”.")
try:
    while True:
        frame = capture_screen()
        detections = detect_objects(frame)
        direction = decide_direction(detections, frame.shape[1])
        press_key(direction)

        # ESC í‚¤ ëˆ„ë¥´ë©´ ì¢…ë£Œ
        if keyboard.is_pressed('esc'):
            break

        time.sleep(0.1)  # 10 FPS ì •ë„ë¡œ ì¡°ì ˆ
finally:
    keyboard.release('a')
    keyboard.release('d')
    print("ğŸ›‘ ììœ¨ì£¼í–‰ ì¢…ë£Œ.")
