import os
import torchaudio
from transformers import MusicgenForConditionalGeneration, AutoProcessor
from pathlib import Path
import torch

def main():
    # ğŸ”¹ 1. í„°ë¯¸ë„ì—ì„œ í…ìŠ¤íŠ¸ ì…ë ¥
    prompt = input("ğŸ¤ Enter a text prompt for music generation: ").strip()
    if not prompt:
        print("âŒ No prompt provided. Exiting.")
        return

    # ğŸ”¹ 2. ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path("outputs/audio")
    output_dir.mkdir(parents=True, exist_ok=True)

    # ğŸ”¹ 3. ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ í™•ì¸ ë° ë¡œë”©
    model_dir = Path("models/musicgen-small")
    if model_dir.exists():
        print("âœ… Loading model and processor from local 'models/' directory.")
        model = MusicgenForConditionalGeneration.from_pretrained(model_dir)
        processor = AutoProcessor.from_pretrained(model_dir)
    else:
        print("â¬‡ï¸ Downloading model and saving to 'models/musicgen-small'...")
        model = MusicgenForConditionalGeneration.from_pretrained("facebook/musicgen-small")
        processor = AutoProcessor.from_pretrained("facebook/musicgen-small")
        model.save_pretrained(model_dir)
        processor.save_pretrained(model_dir)

    # ğŸ”¹ 4. í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ìŒì•… ìƒì„±
    inputs = processor(text=[prompt], return_tensors="pt")
    with torch.no_grad():
        audio_values = model.generate(**inputs, max_new_tokens=1024)

    # ğŸ”¹ 5. ì˜¤ë””ì˜¤ ì €ì¥
    filename = prompt.replace(" ", "_")[:50] + ".wav"
    filepath = output_dir / filename
    torchaudio.save(str(filepath), audio_values[0], 32000)
    print(f"ğŸµ Audio generated and saved to: {filepath}")

if __name__ == "__main__":
    main()
